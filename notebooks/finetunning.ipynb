{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6\n",
    "\n",
    "What I expect from this chapter:\n",
    "\n",
    "- Learn what fine-tuning is for LLMs.\n",
    "- Learn what can I achieve by finetunning an LLM. How is it better than the original model?\n",
    "- Learn how much data do I need to fine-tune an LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM fine tuning generally split in two types:\n",
    "\n",
    "- **Instruction**: Learn to follow instructions, rather than just complete text.\n",
    "- **Classification**: Learn to classify text in predefined categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "name = \"SMSSpamCollection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is only 200kb, so consider loading into memory instead of extracting the content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(url: str, name: str) -> pd.DataFrame:\n",
    "    res = requests.get(url)\n",
    "    zip = zipfile.ZipFile(io.BytesIO(res.content))\n",
    "    df = pd.read_csv(zip.open(name), sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_data(url, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset unbalanced. Contains much more ham than spam.\n",
    "\n",
    "We'll bruteforce balance it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_balanced_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    spam_subset = df.query(\"Label == 'spam'\")\n",
    "    ham_subset = df.query(\"Label == 'ham'\").sample(\n",
    "        spam_subset.shape[0], random_state=36\n",
    "    )\n",
    "\n",
    "    balanced_df = pd.concat([spam_subset, ham_subset], ignore_index=True)\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipping the balancing step to see difference in results\n",
    "balanced_df = df.copy()\n",
    "\n",
    "# Now, let's create a target value by converting tags to binary values.\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"spam\": 1, \"ham\": 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(\n",
    "    df: pd.DataFrame, train_frac: float, validation_frac: float\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    # Randomize dataset order\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(df.shape[0] * train_frac)\n",
    "    validation_end = train_end + int(df.shape[0] * validation_frac)\n",
    "\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    return train_df, validation_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path().cwd().parent / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_path.exists():\n",
    "    data_path.mkdir()\n",
    "\n",
    "train_df.to_csv(data_path / \"train.csv\", index=None)\n",
    "validation_df.to_csv(data_path / \"validation.csv\", index=None)\n",
    "test_df.to_csv(data_path / \"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combine multiple training examples in a batch, they must have **the same length**.\n",
    "\n",
    "So do one of the following:\n",
    "\n",
    "- Truncate all messages to length of shortest.\n",
    "- Pad all messagest to length of largest.\n",
    "\n",
    "Choose the later to not lose information. Use 50256 token (endoftext) as padding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50256]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_file: str,\n",
    "        tokenizer: tiktoken.Encoding,\n",
    "        max_length: int | None = None,\n",
    "        pad_token_id: int = 50256,\n",
    "    ):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate text\n",
    "            self.encoded_texts = [\n",
    "                encoded_texts[: self.max_length] for encoded_texts in self.encoded_texts\n",
    "            ]\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.at[index, \"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            max_length = max(max_length, len(encoded_text))\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation and Test datasets that are longer than training are truncated.\n",
    "\n",
    "train_dataset = SpamDataset(\n",
    "    csv_file=data_path / \"train.csv\", max_length=None, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=data_path / \"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=data_path / \"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset._longest_encoded_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8  # how many objects to train at the same time\n",
    "\n",
    "# shuffle=True so model doesn't learn anything from order of docuemnts\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 257])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(input_batch.shape)\n",
    "print(target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487\n",
      "70\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(val_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True,\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpd-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import generate_text_simple, text_to_token_ids, token_ids_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always have a base to compare. Start by checking out if model is capable of classifying spam by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.' Answer with 'yes' or 'no'. Answer with 'yes' or 'no'. Answer with 'yes' or 'no'. Answer with 'yes'\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    "    \" Answer with 'yes' or 'no'.\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is not good at following instructions. It hasn't beenn trained to do so!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing the model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "    in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each input token, one output.\n",
    "\n",
    "The last result contains the most information, as it has information from all previous tokens, due to how the atention mecanism works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function (remember, must be differentiable)\n",
    "\n",
    "\n",
    "# minimize the cross entropy loss\n",
    "def calc_loss_batch(input_batch, target_batch, model, device) -> torch.Tensor:\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0730717897415163\n",
      "2.5822011470794677\n",
      "2.833951997756958\n"
     ]
    }
   ],
   "source": [
    "print(train_loss)\n",
    "print(val_loss)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy is non-diferentaible, so only use for evaluation, not for fine-tunning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()  # Disable gradient tracking for efficiency\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "            logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 53.75%\n",
      "Validation accuracy: 55.00%\n",
      "Test accuracy: 51.25%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous epoch\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[\n",
    "                0\n",
    "            ]  # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.779, Val loss 2.541\n",
      "Ep 1 (Step 000050): Train loss 0.834, Val loss 0.846\n",
      "Ep 1 (Step 000100): Train loss 0.661, Val loss 0.691\n",
      "Training accuracy: 72.50% | Validation accuracy: 57.50%\n",
      "Ep 2 (Step 000150): Train loss 0.696, Val loss 0.704\n",
      "Ep 2 (Step 000200): Train loss 0.673, Val loss 0.680\n",
      "Ep 2 (Step 000250): Train loss 0.675, Val loss 0.679\n",
      "Training accuracy: 65.00% | Validation accuracy: 60.00%\n",
      "Ep 3 (Step 000300): Train loss 0.671, Val loss 0.671\n",
      "Ep 3 (Step 000350): Train loss 0.653, Val loss 0.671\n",
      "Training accuracy: 62.50% | Validation accuracy: 50.00%\n",
      "Ep 4 (Step 000400): Train loss 0.604, Val loss 0.667\n",
      "Ep 4 (Step 000450): Train loss 0.666, Val loss 0.656\n",
      "Ep 4 (Step 000500): Train loss 0.620, Val loss 0.655\n",
      "Training accuracy: 75.00% | Validation accuracy: 70.00%\n",
      "Ep 5 (Step 000550): Train loss 0.653, Val loss 0.646\n",
      "Ep 5 (Step 000600): Train loss 0.624, Val loss 0.646\n",
      "Training accuracy: 80.00% | Validation accuracy: 75.00%\n",
      "Training completed in 5.08 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=50,\n",
    "    eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 85.00%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(\n",
    "    text, model, tokenizer, device, max_length=None, pad_token_id=50256\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[: min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(\n",
    "        0\n",
    "    )  # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"Positive\" if predicted_label == 1 else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    classify_review(\n",
    "        text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\" \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    classify_review(\n",
    "        text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do these results compare to vanilla gpt3.5?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import instructor\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = instructor.from_openai(openai.OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsSpamResponse(BaseModel):\n",
    "    is_spam: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_openai(message: str, client) -> bool:\n",
    "    res = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You're a spam classifying expert.\"},\n",
    "            {\"role\": \"user\", \"content\": message},\n",
    "        ],\n",
    "        response_model=IsSpamResponse,\n",
    "    )\n",
    "    res = res.is_spam\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(data_path / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Takes some time, make async for immediate response.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassify_with_openai\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/pandas/core/frame.py:5239\u001b[0m, in \u001b[0;36mDataFrame.assign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   5236\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   5238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 5239\u001b[0m     data[k] \u001b[38;5;241m=\u001b[39m \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_if_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/pandas/core/common.py:384\u001b[0m, in \u001b[0;36mapply_if_callable\u001b[0;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03mEvaluate possibly callable input using obj and kwargs if it is callable,\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03motherwise return as it is.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m**kwargs\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(maybe_callable):\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmaybe_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_callable\n",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Takes some time, make async for immediate response.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39massign(pred\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m df: \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassify_with_openai\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1496\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard.<locals>.curried\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurried\u001b[39m(x):\n\u001b[0;32m-> 1496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m, in \u001b[0;36mclassify_with_openai\u001b[0;34m(message, client)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_with_openai\u001b[39m(message: \u001b[38;5;28mstr\u001b[39m, client) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mre a spam classifying expert.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIsSpamResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     res \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mis_spam\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/instructor/client.py:91\u001b[0m, in \u001b[0;36mInstructor.create\u001b[0;34m(self, response_model, messages, max_retries, validation_context, strict, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     82\u001b[0m     response_model: \u001b[38;5;28mtype\u001b[39m[T],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T \u001b[38;5;241m|\u001b[39m Awaitable[T]:\n\u001b[1;32m     89\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_kwargs(kwargs)\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/instructor/patch.py:143\u001b[0m, in \u001b[0;36mpatch.<locals>.new_create_sync\u001b[0;34m(response_model, validation_context, max_retries, strict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_create_sync\u001b[39m(\n\u001b[1;32m    133\u001b[0m     response_model: \u001b[38;5;28mtype\u001b[39m[T_Model] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: T_ParamSpec\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_Model:\n\u001b[1;32m    140\u001b[0m     response_model, new_kwargs \u001b[38;5;241m=\u001b[39m handle_response_model(\n\u001b[1;32m    141\u001b[0m         response_model\u001b[38;5;241m=\u001b[39mresponse_model, mode\u001b[38;5;241m=\u001b[39mmode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    142\u001b[0m     )\n\u001b[0;32m--> 143\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mretry_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/instructor/retry.py:152\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_retries must be an int or a `tenacity.Retrying` object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m max_retries:\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m attempt:\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/tenacity/__init__.py:435\u001b[0m, in \u001b[0;36mBaseRetrying.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m{})\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m AttemptManager(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/tenacity/__init__.py:368\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    366\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 368\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/tenacity/__init__.py:390\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/instructor/retry.py:155\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m attempt:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m         stream \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    157\u001b[0m         response \u001b[38;5;241m=\u001b[39m update_total_usage(response, total_usage)\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/openai/resources/chat/completions.py:590\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/openai/_base_client.py:952\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    949\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 952\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    958\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Documents/projects/llm_from_scratch/.venv/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1258\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Takes some time, make async for immediate response.\n",
    "results = test.assign(pred=lambda df: df[\"Text\"].apply(classify_with_openai, client=client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT3.5 accuracy: 79.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPT3.5 accuracy: {results['Label'].eq(results['pred']).mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we finetuned is better at predicting spam than vanilla GPT3.5!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens with results if we don't balance the classes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
